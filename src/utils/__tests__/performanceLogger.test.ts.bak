import { PerformanceLogger } from '../performanceLogger';

// Mock performance.now() for predictable testing
const mockPerformanceNow = jest.fn();
Object.defineProperty(global, 'performance', {
    value: { now: mockPerformanceNow }
});

describe('PerformanceLogger', () => {
  beforeEach(() => {
    jest.clearAllMocks();
  });

    let logger: PerformanceLogger;
    let mockLogFunction: jest.Mock;

    beforeEach(() => {
    jest.clearAllMocks();
        mockLogFunction = jest.fn();
        mockPerformanceNow.mockReset();
        logger = new PerformanceLogger('TestService', {
            verbose: true,
            logFunction: mockLogFunction
        });
    });

    describe('constructor', () => {
  beforeEach(() => {
    jest.clearAllMocks();
  });

        it('should create logger with service name and default options', () => {
            const defaultLogger = new PerformanceLogger('DefaultService');
            expect(defaultLogger).toBeInstanceOf(PerformanceLogger);
        });

        it('should use console.log as default log function', () => {
            const consoleSpy = jest.spyOn(console, 'log').mockImplementation();
            const defaultLogger = new PerformanceLogger('DefaultService', { verbose: true });
            
            defaultLogger.log('test message');
            expect(consoleSpy).toHaveBeenCalledWith('[DefaultService] test message');
            
            consoleSpy.mockRestore();
        });

        it('should set verbose based on NODE_ENV when not specified', () => {
            const originalEnv = process.env.NODE_ENV;
            
            // Test production environment
            process.env.NODE_ENV = 'production';
            const prodLogger = new PerformanceLogger('ProdService');
            prodLogger.log('test');
            expect(mockLogFunction).not.toHaveBeenCalled();
            
            // Test development environment
            process.env.NODE_ENV = 'development';
            const devLogger = new PerformanceLogger('DevService', { logFunction: mockLogFunction });
            devLogger.log('test');
            expect(mockLogFunction).toHaveBeenCalled();
            
            process.env.NODE_ENV = originalEnv;
        });
    });

    describe('startTimer', () => {
  beforeEach(() => {
    jest.clearAllMocks();
  });

        it('should start a timer with current performance time', () => {
            mockPerformanceNow.mockReturnValue(100);
            
            logger.startTimer('testTimer');
            
            expect(mockPerformanceNow).toHaveBeenCalled();
            expect(mockLogFunction).toHaveBeenCalledWith('[TestService] [DÉBUT] testTimer');
        });

        it('should not log when verbose is false', () => {
            const quietLogger = new PerformanceLogger('QuietService', {
                verbose: false,
                logFunction: mockLogFunction
            });
            
            quietLogger.startTimer('testTimer');
            
            expect(mockLogFunction).not.toHaveBeenCalled();
        });
    });

    describe('endTimer', () => {
  beforeEach(() => {
    jest.clearAllMocks();
  });

        it('should end a timer and calculate elapsed time', () => {
            mockPerformanceNow
                .mockReturnValueOnce(100) // start time
                .mockReturnValueOnce(250); // end time
            
            logger.startTimer('testTimer');
            const elapsedTime = logger.endTimer('testTimer');
            
            expect(elapsedTime).toBe(150);
            expect(mockLogFunction).toHaveBeenCalledWith('[TestService] [FIN] testTimer: 150.00ms');
        });

        it('should include label in log when provided', () => {
            mockPerformanceNow
                .mockReturnValueOnce(100)
                .mockReturnValueOnce(200);
            
            logger.startTimer('testTimer');
            logger.endTimer('testTimer', 'custom label');
            
            expect(mockLogFunction).toHaveBeenCalledWith('[TestService] [FIN] testTimer (custom label): 100.00ms');
        });

        it('should return 0 and log error for non-existent timer', () => {
            const elapsedTime = logger.endTimer('nonExistentTimer');
            
            expect(elapsedTime).toBe(0);
            expect(mockLogFunction).toHaveBeenCalledWith('[TestService] [ERREUR] Chronomètre "nonExistentTimer" non démarré');
        });

        it('should remove timer after ending', () => {
            mockPerformanceNow
                .mockReturnValueOnce(100)
                .mockReturnValueOnce(200);
            
            logger.startTimer('testTimer');
            logger.endTimer('testTimer');
            
            // Second call should return 0 since timer was removed
            const secondCall = logger.endTimer('testTimer');
            expect(secondCall).toBe(0);
        });
    });

    describe('log', () => {
  beforeEach(() => {
    jest.clearAllMocks();
  });

        it('should log message with service name prefix when verbose', () => {
            logger.log('test message');
            
            expect(mockLogFunction).toHaveBeenCalledWith('[TestService] test message');
        });

        it('should not log when verbose is false', () => {
            const quietLogger = new PerformanceLogger('QuietService', {
                verbose: false,
                logFunction: mockLogFunction
            });
            
            quietLogger.log('test message');
            
            expect(mockLogFunction).not.toHaveBeenCalled();
        });
    });

    describe('measure', () => {
  beforeEach(() => {
    jest.clearAllMocks();
  });

        it('should measure async function execution time', async () => {
            mockPerformanceNow
                .mockReturnValueOnce(100)
                .mockReturnValueOnce(300);
            
            const asyncFunction = jest.fn().mockResolvedValue('result');
            
            const result = await logger.measure('asyncOperation', asyncFunction);
            
            expect(result).toBe('result');
            expect(asyncFunction).toHaveBeenCalled();
            expect(mockLogFunction).toHaveBeenCalledWith('[TestService] [DÉBUT] asyncOperation');
            expect(mockLogFunction).toHaveBeenCalledWith('[TestService] [FIN] asyncOperation: 200.00ms');
        });

        it('should handle function errors and still log timing', async () => {
            mockPerformanceNow
                .mockReturnValueOnce(100)
                .mockReturnValueOnce(200);
            
            const errorFunction = jest.fn().mockRejectedValue(new Error('Test error'));
            
            await expect(logger.measure('errorOperation', errorFunction)).rejects.toThrow('Test error');
            
            expect(mockLogFunction).toHaveBeenCalledWith('[TestService] [FIN] errorOperation (erreur): 100.00ms');
        });
    });

    describe('setVerbose', () => {
  beforeEach(() => {
    jest.clearAllMocks();
  });

        it('should update verbose setting', () => {
            logger.setVerbose(false);
            logger.log('test message');
            
            expect(mockLogFunction).not.toHaveBeenCalled();
            
            logger.setVerbose(true);
            logger.log('test message');
            
            expect(mockLogFunction).toHaveBeenCalledWith('[TestService] test message');
        });
    });

    describe('captureChecks', () => {
  beforeEach(() => {
    jest.clearAllMocks();
  });

        it('should execute multiple checks in parallel and measure total time', async () => {
            mockPerformanceNow
                .mockReturnValue(100)  // main timer start
                .mockReturnValue(150)  // check 0 start
                .mockReturnValue(160)  // check 0 end
                .mockReturnValue(150)  // check 1 start  
                .mockReturnValue(170)  // check 1 end
                .mockReturnValue(200); // main timer end
            
            const check1 = jest.fn().mockResolvedValue('result1');
            const check2 = jest.fn().mockResolvedValue('result2');
            
            const results = await logger.captureChecks('batchChecks', [check1, check2]);
            
            expect(results).toEqual(['result1', 'result2']);
            expect(check1).toHaveBeenCalled();
            expect(check2).toHaveBeenCalled();
            expect(mockLogFunction).toHaveBeenCalledWith('[TestService] [FIN] batchChecks (2 vérifications): 100.00ms');
        });

        it('should handle errors in individual checks', async () => {
            mockPerformanceNow
                .mockReturnValue(100)
                .mockReturnValue(150)
                .mockReturnValue(160)
                .mockReturnValue(200);
            
            const successCheck = jest.fn().mockResolvedValue('success');
            const errorCheck = jest.fn().mockRejectedValue(new Error('Check failed'));
            
            await expect(
                logger.captureChecks('mixedChecks', [successCheck, errorCheck])
            ).rejects.toThrow('Check failed');
        });
    });

    describe('generateReport', () => {
  beforeEach(() => {
    jest.clearAllMocks();
  });

        it('should generate formatted performance report', () => {
            const operations = [
                { name: 'Operation A', time: 100 },
                { name: 'Operation B', time: 200 },
                { name: 'Operation C', time: 50 }
            ];
            
            const report = PerformanceLogger.generateReport(operations);
            
            expect(report).toContain('=== RAPPORT DE PERFORMANCE ===');
            expect(report).toContain('Temps total: 350.00ms');
            expect(report).toContain('1. Operation B: 200.00ms (57.1%)');
            expect(report).toContain('2. Operation A: 100.00ms (28.6%)');
            expect(report).toContain('3. Operation C: 50.00ms (14.3%)');
        });

        it('should handle empty operations array', () => {
            const report = PerformanceLogger.generateReport([]);
            
            expect(report).toContain('Temps total: 0.00ms');
            expect(report).toContain('Détail des opérations:');
        });

        it('should handle single operation', () => {
            const operations = [{ name: 'Single Operation', time: 123.45 }];
            
            const report = PerformanceLogger.generateReport(operations);
            
            expect(report).toContain('Temps total: 123.45ms');
            expect(report).toContain('1. Single Operation: 123.45ms (100.0%)');
        });

        it('should sort operations by execution time (slowest first)', () => {
            const operations = [
                { name: 'Fast', time: 10 },
                { name: 'Slow', time: 100 },
                { name: 'Medium', time: 50 }
            ];
            
            const report = PerformanceLogger.generateReport(operations);
            
            const lines = report.split('
');
            expect(lines.find(line => line.includes('1.'))).toContain('Slow');
            expect(lines.find(line => line.includes('2.'))).toContain('Medium');
            expect(lines.find(line => line.includes('3.'))).toContain('Fast');
        });

        it('should calculate percentages correctly', () => {
            const operations = [
                { name: 'Op1', time: 75 },
                { name: 'Op2', time: 25 }
            ];
            
            const report = PerformanceLogger.generateReport(operations);
            
            expect(report).toContain('Op1: 75.00ms (75.0%)');
            expect(report).toContain('Op2: 25.00ms (25.0%)');
        });
    });

    describe('integration scenarios', () => {
  beforeEach(() => {
    jest.clearAllMocks();
  });

        it('should handle multiple concurrent timers', () => {
            mockPerformanceNow
                .mockReturnValueOnce(100)  // timer1 start
                .mockReturnValueOnce(150)  // timer2 start
                .mockReturnValueOnce(200)  // timer1 end
                .mockReturnValueOnce(250); // timer2 end
            
            logger.startTimer('timer1');
            logger.startTimer('timer2');
            
            const elapsed1 = logger.endTimer('timer1');
            const elapsed2 = logger.endTimer('timer2');
            
            expect(elapsed1).toBe(100);
            expect(elapsed2).toBe(100);
        });

        it('should work with real async operations', async () => {
            // Use real performance.now for this test
            mockPerformanceNow.mockImplementation(() => performance.now());
            
            const realLogger = new PerformanceLogger('RealTest', {
                verbose: true,
                logFunction: mockLogFunction
            });
            
            const delay = (ms: number) => new Promise(resolve => setTimeout(resolve, ms));
            
            const result = await realLogger.measure('realDelay', () => delay(10));
            
            expect(result).toBeUndefined();
            expect(mockLogFunction).toHaveBeenCalledWith(expect.stringContaining('[DÉBUT] realDelay'));
            expect(mockLogFunction).toHaveBeenCalledWith(expect.stringMatching(/\[FIN\] realDelay: \d+\.\d+ms/));
        });

        it('should provide consistent service name across all logs', () => {
            const serviceName = 'ConsistentService';
            const testLogger = new PerformanceLogger(serviceName, {
                verbose: true,
                logFunction: mockLogFunction
            });
            
            mockPerformanceNow
                .mockReturnValueOnce(100)
                .mockReturnValueOnce(200);
            
            testLogger.log('custom message');
            testLogger.startTimer('test');
            testLogger.endTimer('test');
            
            expect(mockLogFunction).toHaveBeenCalledWith(`[${serviceName}] custom message`);
            expect(mockLogFunction).toHaveBeenCalledWith(`[${serviceName}] [DÉBUT] test`);
            expect(mockLogFunction).toHaveBeenCalledWith(`[${serviceName}] [FIN] test: 100.00ms`);
        });
    });
});